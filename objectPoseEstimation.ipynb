{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "# Load previously saved data\n",
    "with np.load('CameraParams.npz') as file:\n",
    "    mtx, dist, rvecs, tvecs = [file[i] for i in ('cameraMatrix','dist','rvecs','tvecs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cameraPoseFromHomography(H):  \n",
    "    norm1 = np.linalg.norm(H[:, 0])\n",
    "    norm2 = np.linalg.norm(H[:, 1])\n",
    "    tnorm = (norm1 + norm2) / 2.0\n",
    "\n",
    "    H1 = H[:, 0] / norm1\n",
    "    H2 = H[:, 1] / norm2\n",
    "    H3 = np.cross(H1, H2)\n",
    "    T = H[:, 2] / tnorm\n",
    "\n",
    "    return np.array([H1, H2, H3, T]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.31206192e-01 -9.92519265e-01  5.40494139e-04]\n",
      " [ 3.64488487e-01  1.22084899e-01  2.59285044e-03]\n",
      " [-1.78071760e-03  8.86435164e-04  2.48075631e-01]] [1083.38624044  390.63159135    2.28935262]\n",
      "[[-0.00396169]\n",
      " [ 0.01232281]\n",
      " [ 2.10843145]] [1083.38624044  390.63159135    2.28935262]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "  \n",
    "# Завантаження зображень \n",
    "image1 = cv2.imread('objImages/1.jpg')  \n",
    "image1 = cv2.resize(image1, (480, 480))\n",
    "image2 = cv2.imread('objImages/5.jpg') \n",
    "image2 = cv2.resize(image2, (620, 480))\n",
    "\n",
    "sift = cv2.SIFT_create() \n",
    "\n",
    "  \n",
    "keypoints1, descriptors1 = sift.detectAndCompute(image1, None) \n",
    "keypoints2, descriptors2 = sift.detectAndCompute(image2, None) \n",
    "\n",
    "BFMatch = cv2.BFMatcher(cv2.NORM_L2) \n",
    "Matches = BFMatch.knnMatch(descriptors1, descriptors2, k=2) \n",
    "\n",
    "good_matches = []\n",
    "for m, n in Matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "\n",
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "result = cameraPoseFromHomography(H)\n",
    "R = result[:, :-1]\n",
    "t = result[:, -1]\n",
    "print(R, t)\n",
    "R, _ = cv2.Rodrigues(R)\n",
    "print(R, t)\n",
    "\n",
    "matchesMask = mask.ravel().tolist()\n",
    "h,w = image1.shape[:2]\n",
    "pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_estimatePoseSingleMarkers(corners, marker_size, mtx, distortion):\n",
    "    marker_points = np.array([[-marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, marker_size / 2, 0],\n",
    "                              [marker_size / 2, -marker_size / 2, 0],\n",
    "                              [-marker_size / 2, -marker_size / 2, 0]], dtype=np.float32)\n",
    "\n",
    "    nada, R, t = cv2.solvePnP(marker_points, corners, mtx, distortion, False, cv2.SOLVEPNP_IPPE_SQUARE)\n",
    "\n",
    "    return np.array(R), np.array(t), nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = cv2.perspectiveTransform(pts, H)[::-1]\n",
    "\n",
    "rvec, tvec, markerPoints = my_estimatePoseSingleMarkers(corners, 0.02, mtx, dist)\n",
    "\n",
    "img3 = image2\n",
    "img3 = cv2.drawFrameAxes(img3, mtx, dist, rvec, tvec, 0.01)  \n",
    "\n",
    "for corner in corners:\n",
    "        x, y = corner[0]\n",
    "        frame = cv2.circle(img3, (int(x), int(y)), 5, (0, 0, 255), -1) \n",
    "\n",
    "img3 = cv2.resize(img3, (600, 600))\n",
    "cv2.imshow(\"result\", img3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_estimation(frame, mtx, dist, sift, keypoints1, descriptors1):\n",
    "    grey_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(grey_frame, None) \n",
    "    \n",
    "    try:\n",
    "        BFMatch = cv2.BFMatcher() \n",
    "        Matches = BFMatch.knnMatch(descriptors1, descriptors2, k=2) \n",
    "\n",
    "        # Фільтрація матчів за допомогою ratio test \n",
    "        good_matches = []\n",
    "        for m, n in Matches:\n",
    "            if m.distance < 0.7 * n.distance:\n",
    "                good_matches.append(m)\n",
    "\n",
    "\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        h,w = image1.shape[:2]\n",
    "        pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "        corners = cv2.perspectiveTransform(pts, H)\n",
    "    except:\n",
    "        return frame\n",
    "\n",
    "    corners = corners[::-1]\n",
    "    rvec, tvec, markerPoints = my_estimatePoseSingleMarkers(corners, 0.02, mtx, dist)\n",
    "\n",
    "    frame = cv2.drawFrameAxes(frame, mtx, dist, rvec, tvec, 0.01)  \n",
    "\n",
    "    for corner in corners:\n",
    "        x, y = corner[0]\n",
    "        frame = cv2.circle(frame, (int(x), int(y)), 5, (0, 0, 255), -1) \n",
    "    \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "sift = cv2.SIFT_create() \n",
    "\n",
    "image1 = cv2.imread('objImages/1.jpg')  \n",
    "image1 = cv2.resize(image1, (480, 480))\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "keypoints1, descriptors1 = sift.detectAndCompute(image1, None) \n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, img = cap.read()\n",
    "\n",
    "    timer = cv2.getTickCount()\n",
    "    \n",
    "    frame = pose_estimation(img, mtx, dist, sift, keypoints1, descriptors1)\n",
    "\n",
    "    fps = cv2.getTickFrequency() / (cv2.getTickCount() - timer)\n",
    "\n",
    "    frame = cv2.putText(frame, f'{int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 170, 50), 3)\n",
    "    cv2.imshow('Estimated Pose', frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
